# æ™ºèƒ½åˆ‡ç«¹æœºæ¨¡å‹å­˜å‚¨

## ğŸ“ ç›®å½•ç»“æ„
```
models/
â”œâ”€â”€ README.md              # æœ¬è¯´æ˜æ–‡æ¡£
â”œâ”€â”€ best_model.pt          # è®­ç»ƒå¥½çš„YOLOæ¨¡å‹ (PyTorchæ ¼å¼)
â”œâ”€â”€ best_model.onnx        # ONNXæ ¼å¼æ¨¡å‹ (å¯é€‰ï¼Œç”¨äºéƒ¨ç½²ä¼˜åŒ–)
â””â”€â”€ model_info.json       # æ¨¡å‹ä¿¡æ¯æ–‡ä»¶
```

## ğŸ“ æ¨¡å‹æ–‡ä»¶è¯´æ˜

### ä¸»è¦æ¨¡å‹æ–‡ä»¶
- **best_model.pt**: è®­ç»ƒå¥½çš„PyTorchæ¨¡å‹æƒé‡æ–‡ä»¶
- **best_model.onnx**: ONNXæ ¼å¼æ¨¡å‹ï¼Œç”¨äºè·¨å¹³å°éƒ¨ç½²
- **model_info.json**: æ¨¡å‹å…ƒæ•°æ®ä¿¡æ¯

## ğŸ”§ ä½¿ç”¨æ–¹æ³•

### 1. åŠ è½½PyTorchæ¨¡å‹
```python
import torch
from ultralytics import YOLO

# åŠ è½½æ¨¡å‹
model_path = "models/best_model.pt"
model = YOLO(model_path)

# è¿›è¡Œæ¨ç†
results = model.predict(source="image.jpg")
```

### 2. åŠ è½½ONNXæ¨¡å‹
```python
import onnxruntime as ort

# åŠ è½½ONNXæ¨¡å‹
model_path = "models/best_model.onnx"
session = ort.InferenceSession(model_path)

# è¿›è¡Œæ¨ç†
# inputs = {...}  # å‡†å¤‡è¾“å…¥æ•°æ®
# outputs = session.run(None, inputs)
```

## ğŸ“Š æ¨¡å‹ä¿¡æ¯æ¨¡æ¿

åˆ›å»º `model_info.json` æ–‡ä»¶åŒ…å«ä»¥ä¸‹ä¿¡æ¯ï¼š
```json
{
  "model_name": "bamboo_detector",
  "version": "1.0",
  "framework": "YOLOv8",
  "created_date": "2024-02-15",
  "input_size": [640, 640],
  "classes": ["bamboo_node", "bamboo_segment"],
  "performance": {
    "mAP": 0.95,
    "precision": 0.93,
    "recall": 0.97
  },
  "file_size_mb": 50.2,
  "inference_time_ms": 45
}
```

---
**æœ€åæ›´æ–°**: 2024å¹´2æœˆ15æ—¥ 